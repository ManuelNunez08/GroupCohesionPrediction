{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, lets now put together a few machine learning models to have as a benchmark. These will aggregate across node features (leaving edge features out for now) to set a baseline for GNNs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets start by loading in the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Meeting</th>\n",
       "      <th>ParticipantID</th>\n",
       "      <th>Start Time</th>\n",
       "      <th>time_portion</th>\n",
       "      <th>speaking_turns_proportion</th>\n",
       "      <th>rate_of_speech</th>\n",
       "      <th>lexical_richness</th>\n",
       "      <th>positive_sentiment_proportion</th>\n",
       "      <th>negative_sentiment_proportion</th>\n",
       "      <th>average_word_rarity</th>\n",
       "      <th>first_person_pronoun_usage</th>\n",
       "      <th>second_person_pronoun_usage</th>\n",
       "      <th>third_person_pronoun_usage</th>\n",
       "      <th>agreement_words_proportion</th>\n",
       "      <th>disagreement_words_proportion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IS1000a</td>\n",
       "      <td>A</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>0.061873</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.594406</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IS1000a</td>\n",
       "      <td>B</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>0.306594</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.302286</td>\n",
       "      <td>0.641026</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.085470</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IS1000a</td>\n",
       "      <td>C</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>0.504586</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.538158</td>\n",
       "      <td>0.520270</td>\n",
       "      <td>0.024194</td>\n",
       "      <td>0.008065</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.006757</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013514</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IS1000a</td>\n",
       "      <td>D</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>0.350035</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.917182</td>\n",
       "      <td>0.533898</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050847</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025424</td>\n",
       "      <td>0.025424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IS1000a</td>\n",
       "      <td>A</td>\n",
       "      <td>1320.0</td>\n",
       "      <td>0.167932</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.951561</td>\n",
       "      <td>0.586957</td>\n",
       "      <td>0.012821</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000285</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.010870</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Meeting ParticipantID  Start Time  time_portion  speaking_turns_proportion  \\\n",
       "0  IS1000a             A      1200.0      0.061873                        0.0   \n",
       "1  IS1000a             B      1200.0      0.306594                        0.2   \n",
       "2  IS1000a             C      1200.0      0.504586                        0.6   \n",
       "3  IS1000a             D      1200.0      0.350035                        0.2   \n",
       "4  IS1000a             A      1320.0      0.167932                        0.2   \n",
       "\n",
       "   rate_of_speech  lexical_richness  positive_sentiment_proportion  \\\n",
       "0        5.594406          0.250000                       0.000000   \n",
       "1        3.302286          0.641026                       0.030303   \n",
       "2        2.538158          0.520270                       0.024194   \n",
       "3        2.917182          0.533898                       0.057143   \n",
       "4        4.951561          0.586957                       0.012821   \n",
       "\n",
       "   negative_sentiment_proportion  average_word_rarity  \\\n",
       "0                       0.000000             0.000074   \n",
       "1                       0.000000             0.000180   \n",
       "2                       0.008065             0.000223   \n",
       "3                       0.000000             0.000228   \n",
       "4                       0.000000             0.000285   \n",
       "\n",
       "   first_person_pronoun_usage  second_person_pronoun_usage  \\\n",
       "0                    0.000000                     0.000000   \n",
       "1                    0.000000                     0.025641   \n",
       "2                    0.006757                     0.054054   \n",
       "3                    0.000000                     0.050847   \n",
       "4                    0.000000                     0.000000   \n",
       "\n",
       "   third_person_pronoun_usage  agreement_words_proportion  \\\n",
       "0                         0.0                    0.000000   \n",
       "1                         0.0                    0.085470   \n",
       "2                         0.0                    0.013514   \n",
       "3                         0.0                    0.025424   \n",
       "4                         0.0                    0.021739   \n",
       "\n",
       "   disagreement_words_proportion  \n",
       "0                       0.000000  \n",
       "1                       0.000000  \n",
       "2                       0.000000  \n",
       "3                       0.025424  \n",
       "4                       0.010870  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_features_df = pd.read_pickle('../graphs/data/node_features_df.pkl')\n",
    "node_features_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we an now comprss features with the df below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Meeting</th>\n",
       "      <th>Start Time</th>\n",
       "      <th>Start Time_min</th>\n",
       "      <th>Start Time_max</th>\n",
       "      <th>Start Time_mean</th>\n",
       "      <th>Start Time_std</th>\n",
       "      <th>time_portion_min</th>\n",
       "      <th>time_portion_max</th>\n",
       "      <th>time_portion_mean</th>\n",
       "      <th>time_portion_std</th>\n",
       "      <th>...</th>\n",
       "      <th>third_person_pronoun_usage_mean</th>\n",
       "      <th>third_person_pronoun_usage_std</th>\n",
       "      <th>agreement_words_proportion_min</th>\n",
       "      <th>agreement_words_proportion_max</th>\n",
       "      <th>agreement_words_proportion_mean</th>\n",
       "      <th>agreement_words_proportion_std</th>\n",
       "      <th>disagreement_words_proportion_min</th>\n",
       "      <th>disagreement_words_proportion_max</th>\n",
       "      <th>disagreement_words_proportion_mean</th>\n",
       "      <th>disagreement_words_proportion_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IS1000a</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.061873</td>\n",
       "      <td>0.504586</td>\n",
       "      <td>0.305772</td>\n",
       "      <td>0.183461</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.085470</td>\n",
       "      <td>0.031102</td>\n",
       "      <td>0.037704</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.025424</td>\n",
       "      <td>0.006356</td>\n",
       "      <td>0.012712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IS1000a</td>\n",
       "      <td>1320.0</td>\n",
       "      <td>1320.0</td>\n",
       "      <td>1320.0</td>\n",
       "      <td>1320.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.167932</td>\n",
       "      <td>0.389732</td>\n",
       "      <td>0.281295</td>\n",
       "      <td>0.091612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005288</td>\n",
       "      <td>0.006166</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>0.035875</td>\n",
       "      <td>0.011140</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.005098</td>\n",
       "      <td>0.005913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IS1000b</td>\n",
       "      <td>300.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.574545</td>\n",
       "      <td>0.260003</td>\n",
       "      <td>0.280661</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003676</td>\n",
       "      <td>0.007353</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095890</td>\n",
       "      <td>0.025811</td>\n",
       "      <td>0.046848</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.036765</td>\n",
       "      <td>0.010904</td>\n",
       "      <td>0.017541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IS1000b</td>\n",
       "      <td>420.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011573</td>\n",
       "      <td>0.796130</td>\n",
       "      <td>0.258217</td>\n",
       "      <td>0.364977</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005016</td>\n",
       "      <td>0.006176</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.073717</td>\n",
       "      <td>0.037866</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.013215</td>\n",
       "      <td>0.021775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IS1000b</td>\n",
       "      <td>600.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.206471</td>\n",
       "      <td>0.282437</td>\n",
       "      <td>0.244748</td>\n",
       "      <td>0.032408</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039474</td>\n",
       "      <td>0.115044</td>\n",
       "      <td>0.074254</td>\n",
       "      <td>0.031857</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.039474</td>\n",
       "      <td>0.024606</td>\n",
       "      <td>0.013244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Meeting  Start Time  Start Time_min  Start Time_max  Start Time_mean  \\\n",
       "0  IS1000a      1200.0          1200.0          1200.0           1200.0   \n",
       "1  IS1000a      1320.0          1320.0          1320.0           1320.0   \n",
       "2  IS1000b       300.0           300.0           300.0            300.0   \n",
       "3  IS1000b       420.0           420.0           420.0            420.0   \n",
       "4  IS1000b       600.0           600.0           600.0            600.0   \n",
       "\n",
       "   Start Time_std  time_portion_min  time_portion_max  time_portion_mean  \\\n",
       "0             0.0          0.061873          0.504586           0.305772   \n",
       "1             0.0          0.167932          0.389732           0.281295   \n",
       "2             0.0          0.000000          0.574545           0.260003   \n",
       "3             0.0          0.011573          0.796130           0.258217   \n",
       "4             0.0          0.206471          0.282437           0.244748   \n",
       "\n",
       "   time_portion_std  ...  third_person_pronoun_usage_mean  \\\n",
       "0          0.183461  ...                         0.000000   \n",
       "1          0.091612  ...                         0.005288   \n",
       "2          0.280661  ...                         0.003676   \n",
       "3          0.364977  ...                         0.005016   \n",
       "4          0.032408  ...                         0.000000   \n",
       "\n",
       "   third_person_pronoun_usage_std  agreement_words_proportion_min  \\\n",
       "0                        0.000000                        0.000000   \n",
       "1                        0.006166                        0.021739   \n",
       "2                        0.007353                        0.000000   \n",
       "3                        0.006176                        0.037037   \n",
       "4                        0.000000                        0.039474   \n",
       "\n",
       "   agreement_words_proportion_max  agreement_words_proportion_mean  \\\n",
       "0                        0.085470                         0.031102   \n",
       "1                        0.048780                         0.035875   \n",
       "2                        0.095890                         0.025811   \n",
       "3                        0.111111                         0.073717   \n",
       "4                        0.115044                         0.074254   \n",
       "\n",
       "   agreement_words_proportion_std  disagreement_words_proportion_min  \\\n",
       "0                        0.037704                               0.00   \n",
       "1                        0.011140                               0.00   \n",
       "2                        0.046848                               0.00   \n",
       "3                        0.037866                               0.00   \n",
       "4                        0.031857                               0.01   \n",
       "\n",
       "   disagreement_words_proportion_max  disagreement_words_proportion_mean  \\\n",
       "0                           0.025424                            0.006356   \n",
       "1                           0.010870                            0.005098   \n",
       "2                           0.036765                            0.010904   \n",
       "3                           0.045455                            0.013215   \n",
       "4                           0.039474                            0.024606   \n",
       "\n",
       "   disagreement_words_proportion_std  \n",
       "0                           0.012712  \n",
       "1                           0.005913  \n",
       "2                           0.017541  \n",
       "3                           0.021775  \n",
       "4                           0.013244  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "grouped = node_features_df.groupby(['Meeting', 'Start Time'])\n",
    "rows = []\n",
    "\n",
    "for (meeting, start_time), group in grouped:\n",
    "    if len(group) == 4: \n",
    "        # Compute the min, max, mean, and std for each of the 12 features\n",
    "        stats = {\n",
    "            'Meeting': meeting,\n",
    "            'Start Time': start_time\n",
    "        }\n",
    "        for feature in group.columns[2:]:  \n",
    "            stats[f'{feature}_min'] = group[feature].min()\n",
    "            stats[f'{feature}_max'] = group[feature].max()\n",
    "            stats[f'{feature}_mean'] = group[feature].mean()\n",
    "            stats[f'{feature}_std'] = group[feature].std()\n",
    "\n",
    "        \n",
    "        rows.append(stats)\n",
    "\n",
    "# Create a new DataFrame from the list of rows\n",
    "compressed_node_features_df= pd.DataFrame(rows)\n",
    "compressed_node_features_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets load in the cohesion annotations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load question-level scores df \n",
    "question_level_df = pd.read_pickle(\"../Cohesion_Annotations/Question_Split_data.pkl\")\n",
    "category_level_df = pd.read_pickle(\"../Cohesion_Annotations/Cohesion_split_data.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_and_append_category_level(category_level_df, compressed_node_features_df, column_name, kappa_constraint):\n",
    "    # Filter category_level_df for rows where 'Meeting' and 'Start' match compressed_node_features_df\n",
    "    filtered_df = category_level_df[\n",
    "        category_level_df[['Meeting', 'Start']].apply(tuple, axis=1).isin(\n",
    "            compressed_node_features_df[['Meeting', 'Start Time']].apply(tuple, axis=1)\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # Further filter rows where the kappa score for the given column is above the kappa_constraint\n",
    "    filtered_df = filtered_df[filtered_df[column_name + '_Kappa'] >= kappa_constraint]\n",
    "    \n",
    "    # Merge the filtered category_level_df with compressed_node_features_df based on 'Meeting' and 'Start'\n",
    "    merged_df = pd.merge(compressed_node_features_df, filtered_df[['Meeting', 'Start', column_name + '_Average']], \n",
    "                        left_on=['Meeting', 'Start Time'], right_on=['Meeting', 'Start'], how='inner')\n",
    "    \n",
    "    # Return the resulting dataframe with the appended average score column\n",
    "    return merged_df.drop(columns='Start')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize_and_filter(df, column_name, lower_threshold, upper_threshold):\n",
    "    # Create a new binary column based on the thresholds\n",
    "    df['Binary_Column'] = df[column_name].apply(lambda x: 0 if x < lower_threshold else (1 if x > upper_threshold else None))\n",
    "\n",
    "    # Drop rows where the Binary_Column is None (values between the thresholds)\n",
    "    df_filtered = df.dropna(subset=['Binary_Column'])\n",
    "\n",
    "    return df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df = filter_and_append_category_level(category_level_df, compressed_node_features_df, 'Cohesion', 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labeled_df[labeled_df['Cohesion_Average'] < 3.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "binarized_labeled_df = binarize_and_filter(labeled_df, 'Cohesion_Average', 3.5, 4.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Classifier Benchmark (Majority Class: 1.0)\n",
      "Accuracy: 0.8462\n",
      "Precision: 0.8462\n",
      "Recall: 1.0000\n",
      "F1-Score: 0.9167\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Assuming df is your dataframe and 'Binary_Column' is your target variable\n",
    "X = binarized_labeled_df.drop(columns=['Binary_Column'])  # Drop the target variable\n",
    "y = binarized_labeled_df['Binary_Column']  # Target variable\n",
    "\n",
    "# Split the data into training and testing sets (e.g., 80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a naive classifier: predict only the majority class (in this case, '1')\n",
    "majority_class = y_train.mode()[0]  # Find the most frequent class in the training set\n",
    "\n",
    "# Create a dummy prediction for the test set (predicting the majority class for all)\n",
    "y_pred = [majority_class] * len(y_test)\n",
    "\n",
    "# Evaluate the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, zero_division=1)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Output the results\n",
    "print(f\"Naive Classifier Benchmark (Majority Class: {majority_class})\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets start wit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "okay"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EnvCohesionPrediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
