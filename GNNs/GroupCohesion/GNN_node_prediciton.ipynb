{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import torch\n",
    "from torch_geometric.data import Data, Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a sort of test to get aquainted with GNN's lets first try to use them for node level predictions by predicting the sex and native language of meeting participants. We will start with sex, although I would be surprised if any notable differences actually exist. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>Native Language</th>\n",
       "      <th>Months Learning</th>\n",
       "      <th>Influences</th>\n",
       "      <th>Meeting</th>\n",
       "      <th>Letter</th>\n",
       "      <th>Role</th>\n",
       "      <th>Sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>FEE005</td>\n",
       "      <td>English</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ES2002a</td>\n",
       "      <td>B</td>\n",
       "      <td>PM</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FEE005</td>\n",
       "      <td>English</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ES2002b</td>\n",
       "      <td>B</td>\n",
       "      <td>PM</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>FEE005</td>\n",
       "      <td>English</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ES2002c</td>\n",
       "      <td>B</td>\n",
       "      <td>PM</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>FEE005</td>\n",
       "      <td>English</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ES2002d</td>\n",
       "      <td>B</td>\n",
       "      <td>PM</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>MEE006</td>\n",
       "      <td>English</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Mandarin', 'Cantonese']</td>\n",
       "      <td>ES2002a</td>\n",
       "      <td>A</td>\n",
       "      <td>ID</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      ID Native Language  Months Learning  \\\n",
       "0           0  FEE005         English              NaN   \n",
       "1           1  FEE005         English              NaN   \n",
       "2           2  FEE005         English              NaN   \n",
       "3           3  FEE005         English              NaN   \n",
       "4           4  MEE006         English              NaN   \n",
       "\n",
       "                  Influences  Meeting Letter Role Sex  \n",
       "0                        NaN  ES2002a      B   PM   F  \n",
       "1                        NaN  ES2002b      B   PM   F  \n",
       "2                        NaN  ES2002c      B   PM   F  \n",
       "3                        NaN  ES2002d      B   PM   F  \n",
       "4  ['Mandarin', 'Cantonese']  ES2002a      A   ID   M  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "participant_info = pd.read_csv('/Users/manuelnunezmartinez/Documents/UF/Research Internship/code/corpusResources/summary.csv')\n",
    "# Extract sex from the ID column\n",
    "participant_info['Sex'] = participant_info['ID'].apply(lambda x: 'F' if x[0] == 'F' else 'M')\n",
    "participant_info.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 518 entries, 0 to 521\n",
      "Data columns (total 9 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Unnamed: 0       518 non-null    int64  \n",
      " 1   ID               518 non-null    object \n",
      " 2   Native Language  518 non-null    object \n",
      " 3   Months Learning  118 non-null    float64\n",
      " 4   Influences       287 non-null    object \n",
      " 5   Meeting          518 non-null    object \n",
      " 6   Letter           518 non-null    object \n",
      " 7   Role             392 non-null    object \n",
      " 8   Sex              518 non-null    object \n",
      "dtypes: float64(1), int64(1), object(7)\n",
      "memory usage: 40.5+ KB\n"
     ]
    }
   ],
   "source": [
    "participant_info = participant_info.dropna(subset=['Native Language'])\n",
    "participant_info.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of English native speakers: 305\n",
      "Number of non-English native speakers: 213\n"
     ]
    }
   ],
   "source": [
    "# Count the occurrences of \"English\"\n",
    "english_count = participant_info[participant_info['Native Language'] == 'English'].shape[0]\n",
    "\n",
    "# Count the occurrences of non-English languages\n",
    "non_english_count = participant_info[participant_info['Native Language'] != 'English'].shape[0]\n",
    "\n",
    "# Output the counts\n",
    "print(f\"Number of English native speakers: {english_count}\")\n",
    "print(f\"Number of non-English native speakers: {non_english_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we implenent the model necessary for all models built using Pytorch. This dataset must, at the bare minimum overload the following methods: \n",
    "- An Initialization method, which in this case uses a list of meetings and their respective interaction features together with a list of the sex for each participant in each meeting, to compose an \"X and Y\" such that each partiticpants sex is linked to their interactive behavior \n",
    "- A length method to \n",
    "- A method to obtain an entry gievn an index. Note that this requires the dataset to be oridnal such that each X is matched to its respective Y. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we implement the dataset necessary for all models build using "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "class MyGraphDataset(Dataset):\n",
    "    def __init__(self, data_list, participant_info):\n",
    "        super(MyGraphDataset, self).__init__()\n",
    "        self.participant_info = participant_info\n",
    "\n",
    "        # Filter the data_list to only include entries with valid participants\n",
    "        self.data_list = []\n",
    "        for entry in data_list:\n",
    "            meeting, start_time, (node_dic, edge_dic) = entry\n",
    "            valid = True\n",
    "            for node in node_dic.keys():\n",
    "                participant_id = self.participant_info[(self.participant_info['Meeting'] == meeting) & (self.participant_info['Letter'] == node)]['ID']\n",
    "                if participant_id.empty:\n",
    "                    valid = False\n",
    "                    break\n",
    "            if valid:\n",
    "                # Add node info\n",
    "                node_label = {}\n",
    "                for node in node_dic.keys():\n",
    "                    participant_id = self.participant_info[(self.participant_info['Meeting'] == meeting) & (self.participant_info['Letter'] == node)]['ID'].values[0]\n",
    "                    label = self.participant_info[self.participant_info['ID'] == participant_id]['Native Language'].values[0]\n",
    "                    node_label[node] = 0 if label == 'English' else 1  \n",
    "                self.data_list.append((meeting, start_time, (node_dic, edge_dic, node_label)))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        meeting, start_time, (node_dic, edge_dic, node_sex) = self.data_list[idx]\n",
    "\n",
    "        # Create node features tensor\n",
    "        node_features = []\n",
    "        node_labels = []\n",
    "        for node, features in node_dic.items():\n",
    "            node_features.append([feature[1] for feature in features])\n",
    "            node_labels.append(node_sex[node])\n",
    "\n",
    "        x = torch.tensor(node_features, dtype=torch.float)\n",
    "        y = torch.tensor(node_labels, dtype=torch.long)\n",
    "\n",
    "\n",
    "        # Create edge indices and edge features tensor\n",
    "        edge_indices = []\n",
    "        edge_features = []\n",
    "        for edge, features in edge_dic.items():\n",
    "            src, dst = edge.split(',')\n",
    "            src_idx = ord(src) - ord('A')\n",
    "            dst_idx = ord(dst) - ord('A')\n",
    "            edge_indices.append([src_idx, dst_idx])\n",
    "            edge_features.append([feature[1] for feature in features])\n",
    "\n",
    "        edge_index = torch.tensor(edge_indices, dtype=torch.long).t().contiguous()\n",
    "        edge_attr = torch.tensor(edge_features, dtype=torch.float)\n",
    "\n",
    "        return Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the graphs data from file\n",
    "with open('updated_graphs_data.pkl', 'rb') as f:\n",
    "    graphs_data = pickle.load(f)\n",
    "\n",
    "dataset = MyGraphDataset(graphs_data, participant_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "each entry in the datset contains 4 entries: \n",
    "- x: 4 rows X 12 features each, one row per particpant, transformed into a tensor\n",
    "- edge_index: 2 rows X 12 indexes each, to store each permuatation of pairs indexing an edge \n",
    "- edge_attr: 12 rows X 3 features each, storing a transformed tensor of edge features between each pair permutation\n",
    "- y: 4 entries storing the sex of each meeting pariticpant "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.7293e-01, 8.3333e-02, 3.6004e+00, 4.9784e-01, 8.9686e-03, 4.4843e-03,\n",
      "         3.1298e-04, 0.0000e+00, 2.1645e-02, 0.0000e+00, 6.0606e-02, 1.2987e-02],\n",
      "        [5.2905e-01, 6.6667e-01, 3.3207e+00, 4.4310e-01, 4.3928e-02, 1.8088e-02,\n",
      "         3.4122e-04, 0.0000e+00, 2.4213e-02, 2.4213e-03, 4.6005e-02, 1.2107e-02],\n",
      "        [1.3655e-01, 1.6667e-01, 4.1745e+00, 6.2687e-01, 3.9370e-02, 7.8740e-03,\n",
      "         2.9319e-04, 1.4925e-02, 4.4776e-02, 0.0000e+00, 1.4925e-02, 7.4627e-03],\n",
      "        [1.1098e-01, 8.3333e-02, 4.4845e+00, 6.0684e-01, 4.0000e-02, 0.0000e+00,\n",
      "         2.7724e-04, 0.0000e+00, 5.1282e-02, 0.0000e+00, 5.1282e-02, 1.7094e-02]])\n",
      "tensor([[0, 0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 3],\n",
      "        [1, 2, 3, 0, 2, 3, 0, 1, 3, 0, 1, 2]])\n",
      "tensor([[7.0506e-01, 1.7015e-02, 2.8571e+00],\n",
      "        [5.4559e-01, 4.2539e-03, 3.8000e+00],\n",
      "        [4.6247e-01, 1.7015e-02, 1.5000e+00],\n",
      "        [7.0506e-01, 2.9777e-02, 2.6250e+00],\n",
      "        [3.6688e-01, 1.2762e-02, 1.2000e+00],\n",
      "        [3.2383e-01, 4.2539e-03, 5.5000e+00],\n",
      "        [5.4559e-01, 0.0000e+00, 6.0000e+00],\n",
      "        [3.6688e-01, 4.2539e-03, 3.5000e+00],\n",
      "        [6.2388e-01, 0.0000e+00, 9.5000e+00],\n",
      "        [4.6247e-01, 2.9777e-02, 1.0000e+00],\n",
      "        [3.2383e-01, 8.5077e-03, 4.5000e+00],\n",
      "        [6.2388e-01, 4.2539e-03, 5.6667e+00]])\n",
      "tensor([0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0]['x'])\n",
    "print(dataset[0]['edge_index'])\n",
    "print(dataset[0]['edge_attr'])\n",
    "print(dataset[0]['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dataset_for_nonetype(dataset):\n",
    "    total_entries = len(dataset)\n",
    "    none_count = 0\n",
    "    none_indices = []\n",
    "\n",
    "    for idx in range(total_entries):\n",
    "        try:\n",
    "            data = dataset[idx]\n",
    "        except Exception as e:\n",
    "            none_count += 1\n",
    "            none_indices.append(idx)\n",
    "            print(f\"Error at index {idx}: {e}\")\n",
    "\n",
    "    print(f\"Total dataset entries: {total_entries}\")\n",
    "    print(f\"Total NoneType errors: {none_count}\")\n",
    "    print(f\"Indices with NoneType errors: {none_indices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dataset entries: 183\n",
      "Total NoneType errors: 0\n",
      "Indices with NoneType errors: []\n"
     ]
    }
   ],
   "source": [
    "check_dataset_for_nonetype(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[4, 12], edge_index=[2, 12], edge_attr=[12, 3], y=[4])\n"
     ]
    }
   ],
   "source": [
    "data = dataset[0]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we specify the architecture for the model. \n",
    "\n",
    "GNN's are trained through an iterative message passing process that progressivley defines the state of a graph by considering how the features of each node's neighbors deermine its behavior. Each iteration includes in a node's characterization aspects of more distant nodes. A large number of iterations risks creating a homogenous collection of node embeddings, as each node ends up considering all other nodes in its characterization. Thus, we must define the depth of this iterative process in reference to the graphs overall node density. Our \"Conversational Graphs\" are extremley dense given each pariticiapnt has a directed node aimed at every other. Consequently, we will have an extremley shallow iterative process with a single degree of depth. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GCNConv, GATConv\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "\n",
    "NUM_EDGE_FEATURES = 3\n",
    "NUM_NODE_FEATURES = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we have two layer model and a one layer model. The two layers model has been unable to provide accurate clasisfcations for both sex and native language. I predict this is because the two layers are leading to oversmoothing in the iterative message passing process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConversationModel_2Layer(torch.nn.Module):\n",
    "    def __init__(self, num_features=NUM_NODE_FEATURES, hidden_size=32, target_size=1):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_features = num_features\n",
    "        self.target_size = target_size\n",
    "        self.convs = [GATConv(self.num_features, self.hidden_size, edge_dim = NUM_EDGE_FEATURES),\n",
    "                      GATConv(self.hidden_size, self.hidden_size, edge_dim = NUM_EDGE_FEATURES)]\n",
    "        self.linear = nn.Linear(self.hidden_size, self.target_size)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "        for conv in self.convs[:-1]:\n",
    "            x = conv(x, edge_index, edge_attr=edge_attr) \n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, training=self.training)\n",
    "        x = self.convs[-1](x, edge_index, edge_attr=edge_attr)\n",
    "        x = self.linear(x)\n",
    "\n",
    "        return F.sigmoid(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConversationModel_1layer(torch.nn.Module):\n",
    "    def __init__(self, num_features = NUM_NODE_FEATURES, hidden_size=32, target_size=1, dropout=0.5):\n",
    "        super(ConversationModel_1layer, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_features = num_features\n",
    "        self.target_size = target_size\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.conv1 = GATConv(self.num_features, self.hidden_size, edge_dim=NUM_EDGE_FEATURES)\n",
    "        self.linear = nn.Linear(self.hidden_size, self.target_size)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "        x = self.conv1(x, edge_index, edge_attr=edge_attr)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.linear(x)\n",
    "\n",
    "        return torch.sigmoid(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import random_split\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "# Define split\n",
    "total_size = len(dataset)\n",
    "train_size = int(0.7 * total_size)  # 70% for training\n",
    "val_size = int(0.1 * total_size)    # 10% for validation\n",
    "test_size = total_size - train_size - val_size  # 20% for testing\n",
    "\n",
    "data_train, data_val, data_test = random_split(dataset, [train_size, val_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training label distribution: [319 193]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Check the distribution \n",
    "train_labels = []\n",
    "for data in data_train:\n",
    "    train_labels.extend(data.y.cpu().numpy())\n",
    "train_labels = np.array(train_labels)\n",
    "print(\"Training label distribution:\", np.bincount(train_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now move on to model training where we first define epoch, learning rate, etc. parameteres. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = {\n",
    "    'batch_size' : 3, \n",
    "    'save_loss_interval' : 10, \n",
    "    'print_interval' : 25,\n",
    "    'n_epochs' : 500,\n",
    "    'learning_rate' : 0.0005\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, data_iter):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():  \n",
    "        for data in data_iter:\n",
    "            out = model(data).squeeze(-1)  \n",
    "            loss = F.binary_cross_entropy_with_logits(out, data.y.float())  # Use BCE loss\n",
    "            total_loss += loss.item()  \n",
    "\n",
    "    # Normalize the total loss by the number of samples\n",
    "    return total_loss / len(data_iter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, name_prefix, hyperparams):\n",
    "    learning_rate = hyperparams['learning_rate']\n",
    "    batch_size = hyperparams['batch_size']\n",
    "    n_epochs = hyperparams['n_epochs']\n",
    "    save_loss_interval = hyperparams['save_loss_interval']\n",
    "    print_interval = hyperparams['print_interval']\n",
    "    patience = hyperparams.get('patience', 10)  \n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "    loader = DataLoader(data_train, batch_size=batch_size, shuffle=True)\n",
    "    losses = []\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    best_model = None\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        epoch_loss = 0\n",
    "        model.train()\n",
    "        for data in loader:\n",
    "            optimizer.zero_grad()\n",
    "            out = model(data).squeeze(-1)  \n",
    "            loss = F.binary_cross_entropy(out, data.y.float())  \n",
    "            epoch_loss += loss.item() \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        if epoch % save_loss_interval == 0:\n",
    "            val_loss = evaluate_model(model, data_val) / len(data_val)\n",
    "            train_loss = epoch_loss / len(loader.dataset)\n",
    "            if epoch % print_interval == 0:\n",
    "                print(f\"Epoch: {epoch} Train loss: {train_loss:.2e} Validation loss: {val_loss:.2e}\")\n",
    "            losses.append((epoch, train_loss, val_loss))\n",
    "\n",
    "            # Early stopping check\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_model = model.state_dict()  \n",
    "                patience_counter = 0  \n",
    "            else:\n",
    "                patience_counter += 1  \n",
    "\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping triggered after {epoch+1} epochs.\")\n",
    "                model.load_state_dict(best_model)  \n",
    "                break\n",
    "\n",
    "    # Return the best model and losses\n",
    "    return model, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Epoch: 0 Train loss: 2.28e-01 Validation loss: 4.58e-02\n",
      "Epoch: 50 Train loss: 2.17e-01 Validation loss: 4.44e-02\n",
      "Epoch: 100 Train loss: 2.11e-01 Validation loss: 4.41e-02\n",
      "Epoch: 150 Train loss: 1.94e-01 Validation loss: 4.38e-02\n",
      "Epoch: 200 Train loss: 1.75e-01 Validation loss: 4.29e-02\n",
      "Epoch: 250 Train loss: 1.64e-01 Validation loss: 4.24e-02\n",
      "Epoch: 300 Train loss: 1.55e-01 Validation loss: 4.17e-02\n",
      "Epoch: 350 Train loss: 1.46e-01 Validation loss: 4.17e-02\n",
      "Epoch: 400 Train loss: 1.46e-01 Validation loss: 4.09e-02\n",
      "Epoch: 450 Train loss: 1.43e-01 Validation loss: 4.10e-02\n"
     ]
    }
   ],
   "source": [
    "print(\"Training model...\")\n",
    "model = ConversationModel_1layer()\n",
    "model, model_loss_traj = train(model, \"model\", hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.6793\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_loss = evaluate_model(model, data_test)\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal threshold: 0.6072\n",
      "Optimal F1 score: 0.7328\n",
      "Accuracy: 0.7635\n",
      "Precision: 0.7164\n",
      "Recall: 0.7500\n",
      "Final F1 Score: 0.7328\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_curve, f1_score, accuracy_score, precision_score, recall_score\n",
    "\n",
    "model.eval()\n",
    "\n",
    "all_probs = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad(): \n",
    "    for data in data_test:\n",
    "        out = model(data).squeeze(-1)  \n",
    "        probs = torch.sigmoid(out)  \n",
    "        all_probs.append(probs.cpu().numpy())\n",
    "        all_labels.append(data.y.cpu().numpy())\n",
    "\n",
    "# Flatten lists \n",
    "all_probs = np.concatenate(all_probs, axis=0)\n",
    "all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "# Calculate precision, recall, and thresholds\n",
    "precision, recall, thresholds = precision_recall_curve(all_labels, all_probs)\n",
    "\n",
    "f1_scores = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "# Filter out NaN \n",
    "valid_idx = ~np.isnan(f1_scores)\n",
    "valid_f1_scores = f1_scores[valid_idx]\n",
    "valid_thresholds = thresholds[valid_idx[:-1]]  \n",
    "\n",
    "# Find the threshold that maximizes the valid F1 score\n",
    "optimal_idx = np.argmax(valid_f1_scores)\n",
    "optimal_threshold = valid_thresholds[optimal_idx]\n",
    "optimal_f1 = valid_f1_scores[optimal_idx]\n",
    "\n",
    "print(f\"Optimal threshold: {optimal_threshold:.4f}\")\n",
    "print(f\"Optimal F1 score: {optimal_f1:.4f}\")\n",
    "\n",
    "# Evaluate model using the optimal threshold\n",
    "preds = (all_probs >= optimal_threshold).astype(int)\n",
    "\n",
    "# Now calculate the final evaluation metrics based on this threshold\n",
    "accuracy = accuracy_score(all_labels, preds)\n",
    "precision = precision_score(all_labels, preds, zero_division=0)  \n",
    "recall = recall_score(all_labels, preds, zero_division=0)  \n",
    "f1 = f1_score(all_labels, preds, zero_division=0)  \n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"Final F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm = confusion_matrix(all_labels, preds)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, the results are quite promising. The GNN used succesfully employed edge features through GAT's to distinguish Native form Non-Native meeting participants with an accuracy close to 80%. Recognizing that only one layer of convolution was necessary for a fully connected graph, incorporating a dropout layer in training, and finding the optimal sigmoid threshold to split classification all contibuted to the result. Further improvements should include k-fold validation as was done for graph level predicitons. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transcriptionEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
