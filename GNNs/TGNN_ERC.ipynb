{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now use the TGNN architecture employed in other files as a basis to build a model that is able to perform Emotional Recognition Classification. This task involves classifying the emotional state of speaker utterances in multi-party conversation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets first define the pytorch geomrtic dataset. \n",
    "\n",
    "The dataset object taked in a list of graphs where each graph, 'G', is composed of a sub-graphs 'G_i' where each subgraph represents an utterance.  \n",
    "\n",
    "Each subggraph G_i has an entry for Structure, 'X', and one for its emotion label, 'Y'. \n",
    "\n",
    "X contains node entries where each node has a corresponding embedding and list of edges. \n",
    "\n",
    "Consider entry 'X' in graph 'G_0':\n",
    "\n",
    "A dictionary entry for a speaker node will have a full feature embedding and edges pointing to all other nodes in the time stamp as well as an edge pointing to its future state. \n",
    "- Ex. 'D_0': {'embedding': [-0.46728479862213135, -0.20498991012573242, -0.43848446011543274, ....] ,'edges': ['A_0', 'B_0', 'C_0']}\n",
    "\n",
    "A dictionary entry for a silent node will have a null feature embedding and one edge pointing to its future state. \n",
    "- Ex. 'A_0': {'embedding': [NULL] ,'edges': []}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data, Dataset\n",
    "\n",
    "class ERC_Dataset(Dataset):\n",
    "    def __init__(self, data_list):\n",
    "        super(ERC_Dataset, self).__init__()\n",
    "        self.data_list = []\n",
    "\n",
    "        for entry in data_list:\n",
    "            graph_data = entry['G']  \n",
    "            node_names = list(graph_data.keys())  \n",
    "\n",
    "\n",
    "            node_features = []\n",
    "            edge_index = []\n",
    "\n",
    "            # Iterate over each node in the graph to collect embeddings and edge info\n",
    "            for node in node_names:\n",
    "                # Get the node embedding and edges\n",
    "                node_embedding = graph_data[node]['embedding']\n",
    "                edges = graph_data[node]['edges']\n",
    "\n",
    "                # Append node embedding\n",
    "                node_features.append(node_embedding)\n",
    "\n",
    "                # Convert node names into indices and append to edge index\n",
    "                src_idx = node_names.index(node)\n",
    "                for edge_target in edges:\n",
    "                    if edge_target in node_names:\n",
    "                        dst_idx = node_names.index(edge_target)\n",
    "                        edge_index.append([src_idx, dst_idx])\n",
    "\n",
    "                # Convert node features and edge indices to tensors\n",
    "                x = torch.tensor(node_features, dtype=torch.float)\n",
    "                edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "\n",
    "                # Store the binary label as the y label\n",
    "                y = torch.tensor([entry['cohesion_score']], dtype=torch.float)\n",
    "\n",
    "                # Create Geometric Data object with node names as an additional attribute\n",
    "                data = Data(x=x, edge_index=edge_index, y=y)\n",
    "                data.node_names = node_names  # Store node names in the Data object\n",
    "\n",
    "                self.data_list.append(data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data_list[idx]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forward passing should take on the following update steps: \n",
    "\n",
    "\n",
    "For G_i in dataset[i]:\n",
    "    1. update node memories for all listeners replacing null embeddings for memory embedidngs\n",
    "    2. apply message passing in G_i\n",
    "\n",
    "step 1 should call a function with dataset[i] and G_i as a paramete. The function will make put together a sequence of memory states for each listener node and predictthe currnet one which will be used to replace the null embeddings. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "For"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EnvCohesionPrediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
